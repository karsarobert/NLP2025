{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNR9pQMxn/2OXT4FqKW5dTU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c7a1b9364da42bfbf8ef90ffd408588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_785c2e918c7848f8a9b1500819a8c275",
              "IPY_MODEL_171e279158734dadbb5225e3c63eb1b5",
              "IPY_MODEL_17d5aac43541429295e052177bfbed89"
            ],
            "layout": "IPY_MODEL_3693a0c742c84edd8a9f0414d9bd7949"
          }
        },
        "785c2e918c7848f8a9b1500819a8c275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3688bbb41aa45249cd3c2b4981094f3",
            "placeholder": "​",
            "style": "IPY_MODEL_12489e0d03c747c486a3f5ad265487b1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "171e279158734dadbb5225e3c63eb1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08655900949940348eb466454ccc38cb",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_766c7f90e67542f5a652de377740d8c2",
            "value": 48
          }
        },
        "17d5aac43541429295e052177bfbed89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17d97e512d7e4ec9a8a112546f76d8ad",
            "placeholder": "​",
            "style": "IPY_MODEL_4de54bbab5534514a2f8e82a79c538c6",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.04kB/s]"
          }
        },
        "3693a0c742c84edd8a9f0414d9bd7949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3688bbb41aa45249cd3c2b4981094f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12489e0d03c747c486a3f5ad265487b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08655900949940348eb466454ccc38cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "766c7f90e67542f5a652de377740d8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17d97e512d7e4ec9a8a112546f76d8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4de54bbab5534514a2f8e82a79c538c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe4df786519c4831a8d1315a162016bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67c0b633eb6046b6bd429631e1da57a0",
              "IPY_MODEL_9c50072fb8944f06897ae1c00aa64274",
              "IPY_MODEL_e882a5ecb1f844f2ab49106bed3af68d"
            ],
            "layout": "IPY_MODEL_636da1f3558f4d4ab60488b2f66d77e3"
          }
        },
        "67c0b633eb6046b6bd429631e1da57a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce3402e2966543b5800cd4f5a7c7f348",
            "placeholder": "​",
            "style": "IPY_MODEL_1d6ecc9d4dc04c5c92100038c209c3d4",
            "value": "config.json: 100%"
          }
        },
        "9c50072fb8944f06897ae1c00aa64274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5942f9465374cad82c5622203021046",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba9e768f09f6491e9a9b2d0ff00d2fa3",
            "value": 629
          }
        },
        "e882a5ecb1f844f2ab49106bed3af68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_379062dbd2a644169a50639e387beb3c",
            "placeholder": "​",
            "style": "IPY_MODEL_a9ee035361744e5093971c3b27381567",
            "value": " 629/629 [00:00&lt;00:00, 45.8kB/s]"
          }
        },
        "636da1f3558f4d4ab60488b2f66d77e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce3402e2966543b5800cd4f5a7c7f348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d6ecc9d4dc04c5c92100038c209c3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5942f9465374cad82c5622203021046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba9e768f09f6491e9a9b2d0ff00d2fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "379062dbd2a644169a50639e387beb3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ee035361744e5093971c3b27381567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0edeb637c2bc49a885beaa33cfa7f144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c910e8156a5c433ea7e174ca338715c9",
              "IPY_MODEL_686aabab7dd74bc580dc8a246268c5d8",
              "IPY_MODEL_b013df5b64124107bf63e05c0bdbbfbc"
            ],
            "layout": "IPY_MODEL_778c4eb1f87d4fb2b9ea29c3268ad5b7"
          }
        },
        "c910e8156a5c433ea7e174ca338715c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5d86c80b04a47c486562adfb06d0f5e",
            "placeholder": "​",
            "style": "IPY_MODEL_9cd72361e00f4365854c0b30294cf86d",
            "value": "vocab.txt: 100%"
          }
        },
        "686aabab7dd74bc580dc8a246268c5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50ab5b2f74f5412b8cf680563fef4465",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f9e831ae24345b7b4bd11ee3535d9e8",
            "value": 231508
          }
        },
        "b013df5b64124107bf63e05c0bdbbfbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a14229159ff84eb1b0d14369f1127a78",
            "placeholder": "​",
            "style": "IPY_MODEL_044ed8b77e534358867e19636356814d",
            "value": " 232k/232k [00:00&lt;00:00, 645kB/s]"
          }
        },
        "778c4eb1f87d4fb2b9ea29c3268ad5b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5d86c80b04a47c486562adfb06d0f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cd72361e00f4365854c0b30294cf86d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50ab5b2f74f5412b8cf680563fef4465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f9e831ae24345b7b4bd11ee3535d9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a14229159ff84eb1b0d14369f1127a78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044ed8b77e534358867e19636356814d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "651643e178014afaa045a77cd4a5117d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac79e275fbdb4442978b4feea4dfbe96",
              "IPY_MODEL_b92d512797674f7a8243b27856c19131",
              "IPY_MODEL_57d85dc129414a72b0e1f8cb6c8a60a0"
            ],
            "layout": "IPY_MODEL_92867ccc4cc24531b9cc01b51b7045ef"
          }
        },
        "ac79e275fbdb4442978b4feea4dfbe96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24b4b52872134486be5ce84279ff9079",
            "placeholder": "​",
            "style": "IPY_MODEL_76425e51c36449c487ce11ef6206bdc3",
            "value": "model.safetensors: 100%"
          }
        },
        "b92d512797674f7a8243b27856c19131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f337bdbc388443cb388e09c0f4e73f6",
            "max": 267832558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acf2be90fe244b9ca890998dc2c64ec9",
            "value": 267832558
          }
        },
        "57d85dc129414a72b0e1f8cb6c8a60a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5680b652a24294b6521bfbb7abf400",
            "placeholder": "​",
            "style": "IPY_MODEL_868b73539e4f4bc183520756c3f24df3",
            "value": " 268M/268M [00:01&lt;00:00, 242MB/s]"
          }
        },
        "92867ccc4cc24531b9cc01b51b7045ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b4b52872134486be5ce84279ff9079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76425e51c36449c487ce11ef6206bdc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f337bdbc388443cb388e09c0f4e73f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acf2be90fe244b9ca890998dc2c64ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e5680b652a24294b6521bfbb7abf400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868b73539e4f4bc183520756c3f24df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc8df170043c4926b5159ad303d50604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f16b0697a2648609a207e7a30a2d25c",
              "IPY_MODEL_da4d2f761cb4427484f9f307a5eb69e7",
              "IPY_MODEL_a5efe587c8484cf99a023f9950f6a392"
            ],
            "layout": "IPY_MODEL_1d3e6979fa2e49daa66eae152cef9540"
          }
        },
        "9f16b0697a2648609a207e7a30a2d25c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04f2038377d14180a58c858a7464d3be",
            "placeholder": "​",
            "style": "IPY_MODEL_5ebf928b37b5493790be7795221c8645",
            "value": "config.json: 100%"
          }
        },
        "da4d2f761cb4427484f9f307a5eb69e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a9ffb243c794bfc800a3fddce354810",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_725ae13750064d6bb0784cbed652971c",
            "value": 570
          }
        },
        "a5efe587c8484cf99a023f9950f6a392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2e4df79e5f848bbbc209dbbb34092bc",
            "placeholder": "​",
            "style": "IPY_MODEL_62d02e42bcf440528323e4bab7a7f878",
            "value": " 570/570 [00:00&lt;00:00, 20.4kB/s]"
          }
        },
        "1d3e6979fa2e49daa66eae152cef9540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04f2038377d14180a58c858a7464d3be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ebf928b37b5493790be7795221c8645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a9ffb243c794bfc800a3fddce354810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "725ae13750064d6bb0784cbed652971c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2e4df79e5f848bbbc209dbbb34092bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d02e42bcf440528323e4bab7a7f878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03d23d6bb3184bc0ac93903710ca2493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_baea7f8244734ae8995238647facec2c",
              "IPY_MODEL_70f3778f791343519b75dd60f4f47e63",
              "IPY_MODEL_a12bb559db6c48ebb8c5f2ecec948ccf"
            ],
            "layout": "IPY_MODEL_1ea07dacb9564d1fb11f6ca6e3764693"
          }
        },
        "baea7f8244734ae8995238647facec2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ea88943e714e3ca0abcc68ad220049",
            "placeholder": "​",
            "style": "IPY_MODEL_ee0562b48cf74466952a8e4b29ea3e4e",
            "value": "model.safetensors: 100%"
          }
        },
        "70f3778f791343519b75dd60f4f47e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_264b6a5a1de5451f8d4b0b7f14422fdb",
            "max": 435755784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_940c2361830f4bb99a711ed4017d973f",
            "value": 435755784
          }
        },
        "a12bb559db6c48ebb8c5f2ecec948ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdfb33b884b945f09d2c9388c72b121e",
            "placeholder": "​",
            "style": "IPY_MODEL_df0d77f71de84c22a59fcbdf88639c1c",
            "value": " 436M/436M [00:02&lt;00:00, 224MB/s]"
          }
        },
        "1ea07dacb9564d1fb11f6ca6e3764693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ea88943e714e3ca0abcc68ad220049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0562b48cf74466952a8e4b29ea3e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "264b6a5a1de5451f8d4b0b7f14422fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940c2361830f4bb99a711ed4017d973f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdfb33b884b945f09d2c9388c72b121e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0d77f71de84c22a59fcbdf88639c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44e83438ee8a4acfa2d9b2c4bb0722b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bdee739abc24b52805597e2095a4915",
              "IPY_MODEL_d310a0dfbf22432293a55714bd883f52",
              "IPY_MODEL_65943c32807149ca9b202902e8e1953a"
            ],
            "layout": "IPY_MODEL_bf2fb43dd7b24ea9ab34d81629477339"
          }
        },
        "0bdee739abc24b52805597e2095a4915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa730998438e43109000c62c74bddb69",
            "placeholder": "​",
            "style": "IPY_MODEL_84b557cfa069451ba5b4c590219b220d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d310a0dfbf22432293a55714bd883f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9486bd2c67fc4e0a98457ae1efde5a77",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_516b39610ba242de91d6de369f82bf0e",
            "value": 49
          }
        },
        "65943c32807149ca9b202902e8e1953a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58c01f76467140d3922da1a68eab271e",
            "placeholder": "​",
            "style": "IPY_MODEL_ed99143b9a2843f79e81a975a1a3898d",
            "value": " 49.0/49.0 [00:00&lt;00:00, 3.88kB/s]"
          }
        },
        "bf2fb43dd7b24ea9ab34d81629477339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa730998438e43109000c62c74bddb69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84b557cfa069451ba5b4c590219b220d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9486bd2c67fc4e0a98457ae1efde5a77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516b39610ba242de91d6de369f82bf0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58c01f76467140d3922da1a68eab271e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed99143b9a2843f79e81a975a1a3898d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d4d21c498794fa0b9212fec1dfcb592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78ca4cfdbf8c42e48016cdf1dda9fb7c",
              "IPY_MODEL_c55990d643a040e094190c8f8b560172",
              "IPY_MODEL_6cf36218a2dd40a1801a02be5a2560ae"
            ],
            "layout": "IPY_MODEL_4ba1e3f08d814583ab8368cf63b8c149"
          }
        },
        "78ca4cfdbf8c42e48016cdf1dda9fb7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39c3c9f99b724124856b311c3736b6ef",
            "placeholder": "​",
            "style": "IPY_MODEL_1fd7ecab75a4478d948c4b738d5e7f9a",
            "value": "vocab.txt: 100%"
          }
        },
        "c55990d643a040e094190c8f8b560172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3e8c37ce064eb9bc1d32dbae68788d",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd2431c17f144981b785a60c4572ebbf",
            "value": 213450
          }
        },
        "6cf36218a2dd40a1801a02be5a2560ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3e7fbd0fd0947ef93edc2558b22f8c3",
            "placeholder": "​",
            "style": "IPY_MODEL_63e8c3f10e7e4cedb59364648538f197",
            "value": " 213k/213k [00:00&lt;00:00, 621kB/s]"
          }
        },
        "4ba1e3f08d814583ab8368cf63b8c149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39c3c9f99b724124856b311c3736b6ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd7ecab75a4478d948c4b738d5e7f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c3e8c37ce064eb9bc1d32dbae68788d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd2431c17f144981b785a60c4572ebbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3e7fbd0fd0947ef93edc2558b22f8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e8c3f10e7e4cedb59364648538f197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4debc66025c4854b4f236d18dd48fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87d573f0c4954ce7a338fa69eae726ba",
              "IPY_MODEL_7e9897b1859d44848ec8109c666fa34b",
              "IPY_MODEL_7df91eccd4564d0aac8075a609b85192"
            ],
            "layout": "IPY_MODEL_04fbc851f99b4f96bfbb52acd172d731"
          }
        },
        "87d573f0c4954ce7a338fa69eae726ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a3c990dd38843f7b923dc3209706184",
            "placeholder": "​",
            "style": "IPY_MODEL_dfc25fe5c3414fdbbeafce6051a941fb",
            "value": "tokenizer.json: 100%"
          }
        },
        "7e9897b1859d44848ec8109c666fa34b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f44a007036db462dbe42e3236476a3d7",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29066f6809f54da1b5d0f58f9bd127e1",
            "value": 435797
          }
        },
        "7df91eccd4564d0aac8075a609b85192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_000920a62b8f418983ce5e8593434a3a",
            "placeholder": "​",
            "style": "IPY_MODEL_707b845e5bb8407180722c61a6b3d674",
            "value": " 436k/436k [00:00&lt;00:00, 2.49MB/s]"
          }
        },
        "04fbc851f99b4f96bfbb52acd172d731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a3c990dd38843f7b923dc3209706184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfc25fe5c3414fdbbeafce6051a941fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f44a007036db462dbe42e3236476a3d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29066f6809f54da1b5d0f58f9bd127e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "000920a62b8f418983ce5e8593434a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "707b845e5bb8407180722c61a6b3d674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karsarobert/NLP2025/blob/main/02/NLP2024_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Természetes nyelvfeldolgozás\n",
        "# PTE Gépi tanulás III.\n",
        "\n",
        "## 1. Előadás: transzformerek, tokenizálók\n",
        "### 2025. február 12.\n"
      ],
      "metadata": {
        "id": "MqD2ZFtg18zU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bevezetés**\n",
        "\n",
        "A mai órán a transzformátor modellek használatát fogjuk bemutatni a természetes nyelv feldolgozása (NLP) feladatokban. A transzformátor modellek egy mély tanulási modellcsalád, amelyeket 2017-ben a Google Research kutatói fejlesztettek ki. Azóta forradalmasították az NLP-t, és számos feladatban elérték a legmodernebb eredményeket.\n",
        "\n",
        "**A transzformátor modellek architektúrája**\n",
        "\n",
        "A transzformátor modellek egy \"encoder\" és egy \"decoder\" nevű két részből állnak. Az encoder a bemeneti szöveget egy vektorok sorozatává alakítja át, míg a decoder a vektorok sorozatát egy kimeneti szöveggé alakítja vissza. A transzformátor modellek \"attention\" mechanizmust használnak, amely lehetővé teszi a modell számára, hogy a bemeneti szöveg különböző részeire összpontosítson a kimeneti szöveg különböző részei generálásakor.\n",
        "\n",
        "**A transzformátor modellek előnyei**\n",
        "\n",
        "A transzformátor modellek számos előnnyel járnak a hagyományos NLP modellekkel szemben, mint amilyenek a rekurrens neurális hálózatok (RNN-ek):\n",
        "\n",
        "* **Párhuzamosíthatóság:** A transzformátor modellek könnyen párhuzamosíthatók, ami lehetővé teszi a gyorsabb betanításukat és futtatásukat.\n",
        "* **Hosszabb távú függőségek kezelése:** A transzformátor modellek jobban kezelik a hosszú távú függőségeket a bemeneti szövegben, mint az RNN-ek.\n",
        "* **Jobb teljesítmény a legtöbb NLP feladatban:** A transzformátor modellek a legtöbb NLP feladatban elérték a legmodernebb eredményeket.\n",
        "\n",
        "**Transzformátor modellek használata a Hugging Face Transformers-el**\n",
        "\n",
        "A Hugging Face Transformers egy Python könyvtár, amely megkönnyíti a transzformátor modellek használatát NLP feladatokban. A könyvtár számos előre betanított transzformátor modellt is tartalmaz, amelyeket közvetlenül használhatunk.\n",
        "\n",
        "**A mai órán a következőket fogjuk megtanulni:**\n",
        "\n",
        "* Hogyan töltsünk be és mentsünk el egy transzformátor modellt a Hugging Face Transformers-szel.\n",
        "* Hogyan használjunk egy transzformátor modellt szöveg osztályozására.\n",
        "* Hogyan használjunk egy transzformátor modellt szöveg generálására.\n",
        "\n"
      ],
      "metadata": {
        "id": "uY_2SSi6Pusj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mi történik a pipeline függvényen belül?\n",
        "\n",
        "A pipeline három szakaszból áll:\n",
        "\n",
        "1. Tokenizálás:\n",
        "\n",
        "A nyers szöveget tokenekre (kis egységekre) bontjuk.\n",
        "Speciális tokeneket adunk hozzá (ha a modell megköveteli).\n",
        "Minden tokent összekapcsolunk azonosítójával a modell szókincsében.\n",
        "2. Modell:\n",
        "\n",
        "Betöltjük a modell konfigurációját és súlyait.\n",
        "A tokeneket bemenetként adjuk a modellnek.\n",
        "A modell logitokat ad ki (nagy dimenziójú tenzor).\n",
        "3. Feldolgozás utáni:\n",
        "\n",
        "A logitokat valószínűségekké alakítjuk (SoftMax réteg).\n",
        "Meghatározzuk a pozitív és negatív címkékhez tartozó valószínűségeket."
      ],
      "metadata": {
        "id": "72OHmXmLuCg7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8DHTPc8tbt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d90132-4ff5-4b5d-8e0a-90044a9f29be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (4.25.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pGwT3hgtbt4",
        "outputId": "8b1dd916-c45f-49e6-f8c3-a2e57800f5b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9893580079078674},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for an NLP course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg)\n",
        "\n",
        "**Előfeldolgozás tokenizerrel**\n",
        "\n",
        "Más neurális hálózatokhoz hasonlóan a Transformer modellek sem tudják közvetlenül feldolgozni a nyers szöveget, így a pipeline első lépése a szöveges bemenetek olyan számokká alakítása, amelyek értelmezhetőek a modell számára. Ehhez egy tokenizert használunk, amely a következőkért felelős:\n",
        "\n",
        "* A bemenet szavakra, rész-szavakra vagy szimbólumokra (például írásjelekre) történő felosztása, amelyeket tokeneknek nevezünk.\n",
        "* Minden tokent egy egész számhoz rendelünk.\n",
        "* Olyan további bemenetek hozzáadása, amelyek hasznosak lehetnek a modell számára.\n",
        "\n",
        "Mindezt az előfeldolgozást pontosan ugyanúgy kell elvégezni, mint ahogy a modell előzetes betanítása során történt. Ehhez először le kell töltenünk az információkat a Model Hub-ról.  Ennek érdekében az AutoTokenizer osztályt és annak from_pretrained() metódusát használjuk.  A modellünk checkpoint nevének használatával ez automatikusan lekéri a modell tokenizálóhoz kapcsolódó adatokat, és a gyorsítótárba helyezi őket (így csak akkor töltődik le, amikor először futtatod az alábbi kódot).\n",
        "\n",
        "Mivel a sentiment-analysis pipeline alapértelmezett ellenőrzőpontja a distilbert-base-uncased-finetuned-sst-2-english (a modeladatlapot itt tekintheted meg), a következő kódot futtatjuk:\n"
      ],
      "metadata": {
        "id": "631DtvIOvld7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjdl9zTTtbt5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "8c7a1b9364da42bfbf8ef90ffd408588",
            "785c2e918c7848f8a9b1500819a8c275",
            "171e279158734dadbb5225e3c63eb1b5",
            "17d5aac43541429295e052177bfbed89",
            "3693a0c742c84edd8a9f0414d9bd7949",
            "e3688bbb41aa45249cd3c2b4981094f3",
            "12489e0d03c747c486a3f5ad265487b1",
            "08655900949940348eb466454ccc38cb",
            "766c7f90e67542f5a652de377740d8c2",
            "17d97e512d7e4ec9a8a112546f76d8ad",
            "4de54bbab5534514a2f8e82a79c538c6",
            "fe4df786519c4831a8d1315a162016bb",
            "67c0b633eb6046b6bd429631e1da57a0",
            "9c50072fb8944f06897ae1c00aa64274",
            "e882a5ecb1f844f2ab49106bed3af68d",
            "636da1f3558f4d4ab60488b2f66d77e3",
            "ce3402e2966543b5800cd4f5a7c7f348",
            "1d6ecc9d4dc04c5c92100038c209c3d4",
            "a5942f9465374cad82c5622203021046",
            "ba9e768f09f6491e9a9b2d0ff00d2fa3",
            "379062dbd2a644169a50639e387beb3c",
            "a9ee035361744e5093971c3b27381567",
            "0edeb637c2bc49a885beaa33cfa7f144",
            "c910e8156a5c433ea7e174ca338715c9",
            "686aabab7dd74bc580dc8a246268c5d8",
            "b013df5b64124107bf63e05c0bdbbfbc",
            "778c4eb1f87d4fb2b9ea29c3268ad5b7",
            "d5d86c80b04a47c486562adfb06d0f5e",
            "9cd72361e00f4365854c0b30294cf86d",
            "50ab5b2f74f5412b8cf680563fef4465",
            "5f9e831ae24345b7b4bd11ee3535d9e8",
            "a14229159ff84eb1b0d14369f1127a78",
            "044ed8b77e534358867e19636356814d"
          ]
        },
        "outputId": "08246c09-e2e8-4c77-8d6c-46ce81310f5f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c7a1b9364da42bfbf8ef90ffd408588"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe4df786519c4831a8d1315a162016bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0edeb637c2bc49a885beaa33cfa7f144"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Miután rendelkezünk a tokenizerrel, közvetlenül átadhatjuk neki a mondatainkat, és visszakapunk egy szótárat, amely készen áll az adatok modellbe való betáplálásra! Az egyetlen még hátralévő teendő az input ID-k listájának tenzorokká alakítása.**\n",
        "\n",
        "A 🤗 Transformers alkalmazását használhatod úgy, hogy nem kell aggódnod az ML keretrendszer miatt, ami a háttérben fut; lehet ez PyTorch, TensorFlow, vagy akár Flax bizonyos modellek esetében. Habár a Transformer modellek csak **tenzorokat** fogadnak el bemenetként. Ha még sosem hallottál tenzorokról, tekints rájuk úgy, mint NumPy tömbökre.  Egy NumPy tömb lehet egy skalár (0D), egy vektor (1D), egy mátrix (2D), vagy több dimenziós. Ez gyakorlatilag egy tenzor; más ML keretrendszerek tenzorjai hasonló módon viselkednek, és általában ugyanolyan egyszerűen példányosíthatók, mint a NumPy tömbök.\n",
        "\n",
        "Annak meghatározásához, hogy milyen típusú tenzorokat szeretnénk visszakapni (PyTorch, TensorFlow vagy egyszerű NumPy), a return_tensors argumentumot használjuk:\n"
      ],
      "metadata": {
        "id": "JdIyt-0fwodj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hAXM9Mmtbt6",
        "outputId": "e9cf863b-3d8f-4b6c-e2d6-6fbc2a7628d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  2019, 17953,  2361,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ],
      "source": [
        "raw_inputs = [\n",
        "    \"I've been waiting for an NLP course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ne törődj még a paddinggel és a csonkítással (truncation); ezeket később fogjuk megnézni. A legfontosabb dolog, amit érdemes megjegyezni, hogy egyetlen mondatot, vagy mondatok listáját is átadhatsz, valamint meghatározhatod, hogy milyen típusú tenzorokat szeretnél visszakapni (ha nem adsz meg típust, eredményként listák listáját kapod).**\n",
        "\n",
        "Így néznek ki az eredmények PyTorch tenzorként\n",
        "\n",
        "\n",
        "**Maga a kimenet egy dict, szótár, amely két kulcsot tartalmaz: az `input_ids` és az `attention_mask`. Az  `input_ids` minden mondatból a tokenek egyedi azonosítóját tartalmazó egészek két sorát (mondatonként egyet) foglalja magában.\n",
        "\n",
        "\n",
        "Az előre betanított modellünket ugyanúgy tölthetjük le, mint ahogy a tokenizert is tettük. A  🤗 Transformers rendelkezik egy `AutoModel` osztállyal, amelynek szintén van egy `from_pretrained()` metódusa:\n",
        "\n"
      ],
      "metadata": {
        "id": "g51SiKJ9xGIK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgAvnN0wtbt6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "651643e178014afaa045a77cd4a5117d",
            "ac79e275fbdb4442978b4feea4dfbe96",
            "b92d512797674f7a8243b27856c19131",
            "57d85dc129414a72b0e1f8cb6c8a60a0",
            "92867ccc4cc24531b9cc01b51b7045ef",
            "24b4b52872134486be5ce84279ff9079",
            "76425e51c36449c487ce11ef6206bdc3",
            "2f337bdbc388443cb388e09c0f4e73f6",
            "acf2be90fe244b9ca890998dc2c64ec9",
            "5e5680b652a24294b6521bfbb7abf400",
            "868b73539e4f4bc183520756c3f24df3"
          ]
        },
        "outputId": "f8d6d717-e59f-4625-e070-3a4486da6a75"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "651643e178014afaa045a77cd4a5117d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModel.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ebben a kódrészletben ugyanazt a checkpoint-ot töltöttük le, amit korábban a pipeline folyamatunkban használtunk (ennek már a gyorsítótárban kellene lennie), és létrehoztunk egy modellt vele.**\n",
        "\n",
        "Ez az architektúra csak az alap Transformer modult tartalmazza:  adott bemenetekre \"rejtett állapotokat\", más néven \"tulajdonságokat\" (features)  ad ki. Minden egyes modell inputra kapunk egy nagy dimenziós vektort, amely a Transformer modellnek az adott input kontextus szerinti megértését reprezentálja.\n",
        "\n",
        "Ha ez most még nem világos, ne aggódj. Mindezt később elmagyarázzuk.\n",
        "\n",
        "Ezek a rejtett állapotok önmagukban is hasznosak lehetnek, de általában egy másik modellrész, az úgynevezett \"fej\" (head) bemeneteiül szolgálnak.\n",
        "\n",
        "**Miért nagy dimenziós a vektor?**\n",
        "\n",
        "A Transformer modul által előállított vektor általában nagyméretű. Tipikusan három dimenziója van:\n",
        "\n",
        "* **Batch size (kötegméret):** Az egyszerre feldolgozott szekvenciák száma (a példánkban 2).\n",
        "* **Sequence length (szekvenciahossz):** A szekvencia numerikus reprezentációjának hossza (a példánkban 16).\n",
        "* **Hidden size (rejtett méret):** Minden modell input vektorának dimenziója.\n",
        "\n",
        "Azért nevezik \"nagy dimenziójúnak\" az utolsó dimenziószám miatt. A rejtett méret nagyon nagy lehet (a kisebb modelleknél gyakori a 768, a nagyobb modelleknél pedig akár 3072 vagy még nagyobb is lehet).\n",
        "\n",
        "Ezt láthatjuk, ha beadjuk a modellünkbe azokat az inputokat, amelyeket már előre feldolgoztunk:\n"
      ],
      "metadata": {
        "id": "1Wv1FF7tyEiu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq0Lyk74tbt6",
        "outputId": "015b2fa8-85bc-4a2d-afb6-aa410cd71e04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 16, 768])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutput(last_hidden_state=tensor([[[-0.1798,  0.2333,  0.6321,  ..., -0.3017,  0.5008,  0.1481],\n",
              "         [ 0.2758,  0.6497,  0.3200,  ..., -0.0760,  0.5136,  0.1329],\n",
              "         [ 0.9046,  0.0985,  0.2950,  ...,  0.3352, -0.1407, -0.6464],\n",
              "         ...,\n",
              "         [ 0.1466,  0.5661,  0.3235,  ..., -0.3376,  0.5100, -0.0561],\n",
              "         [ 0.7500,  0.0487,  0.1738,  ...,  0.4684,  0.0030, -0.6084],\n",
              "         [ 0.0519,  0.3729,  0.5223,  ...,  0.3584,  0.6500, -0.3883]],\n",
              "\n",
              "        [[-0.2937,  0.7283, -0.1497,  ..., -0.1187, -1.0227, -0.0422],\n",
              "         [-0.2206,  0.9384, -0.0951,  ..., -0.3643, -0.6605,  0.2407],\n",
              "         [-0.1536,  0.8988, -0.0728,  ..., -0.2189, -0.8528,  0.0710],\n",
              "         ...,\n",
              "         [-0.3017,  0.9002, -0.0200,  ..., -0.1082, -0.8412, -0.0861],\n",
              "         [-0.3338,  0.9674, -0.0729,  ..., -0.1952, -0.8181, -0.0634],\n",
              "         [-0.3454,  0.8824, -0.0426,  ..., -0.0993, -0.8329, -0.1065]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "outputs = model(**inputs) #(kettős csillag) operátor kibontja az inputs szótár tartalmát kulcs-érték párokká, és ezeket argumentumként adja át a model konstruktornak.\n",
        "print(outputs.last_hidden_state.shape)\n",
        "outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ne feledd, hogy a Transformers modellek kimenetei úgy viselkednek, mint névvel ellátott rendezett n-esek (namedtuples) vagy szótárak. Az elemekhez hozzáférhetsz attribútumokkal (ahogy az előbb tettük), vagy kulcs szerint (outputs[\"last_hidden_state\"]), vagy akár index segítségével, ha pontosan tudod, hogy mit keresel, hol található (outputs[0]).**\n",
        "\n",
        "**Modell fejek:  Értelmezzük a számokat**\n",
        "\n",
        "A modell fejek a rejtett állapotok nagyméretű vektorát veszik bemenetként, és azt egy másik dimenzióba vetítik. Általában egy vagy néhány lineáris rétegből állnak:\n",
        "\n",
        "![img](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg)\n",
        "\n",
        "**A Transformer modell kimenete közvetlenül a modell következő rétegének fejére kerül.**\n",
        "\n",
        "Ebben a diagramban a modellt az embedding (beágyazó) réteg és az azt követő rétegek jelképezik.  Az embedding réteg minden egyes input azonosítót a tokenizált bemenetben átalakít egy vektorrá, ami a hozzá tartozó tokent reprezentálja. Az azt következő rétegek ezeket a vektorokat manipulálják a figyelemi mechanizmus használatával, hogy létrehozzák a mondatok végső reprezentációját.\n",
        "\n",
        "**A Transformers által nyújtott különböző architektúrák**\n",
        "\n",
        "A Transformers-ben számos különböző architektúra található, amelyek mindegyikét egy-egy meghatározott feladat kezelésére terveztek. Íme egy nem teljeskörű lista:\n",
        "\n",
        "* Model (rejtett állapotok lehívása)\n",
        "* ForCausalLM\n",
        "* ForMaskedLM\n",
        "* ForMultipleChoice\n",
        "* ForQuestionAnswering\n",
        "* ForSequenceClassification\n",
        "* ForTokenClassification\n",
        "* és más architektúrák\n",
        "\n",
        "A saját példánkhoz szükségünk van egy olyan modellre, amely szekvencia osztályozó fejjel rendelkezik (hogy pozitívként vagy negatívként osztályozhassuk a mondatokat).  Így valójában  nem az  `AutoModel` osztályt fogjuk használni, hanem az `AutoModelForSequenceClassification` osztályt:\n"
      ],
      "metadata": {
        "id": "ZtfWFjx6z2hq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgpNXQfftbt6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "outputs = model(**inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ha most megnézzük a kimeneteink alakját, a dimenzionalitás sokkal kisebb lesz: a modellfej bemenetként a korábban látott nagydimenziós vektorokat veszi, és két értéket tartalmazó vektorokat ad ki (címkénként egyet):"
      ],
      "metadata": {
        "id": "PBkki7Np1vld"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZjHaMoytbt7",
        "outputId": "b08df664-0c62-4292-b9d2-bbe9d0a05253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "print(outputs.logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A kimenet utófeldolgozása\n",
        "A modellünk kimeneteként kapott értékeknek önmagukban nem feltétlenül van értelme. Vessünk rá egy pillantást:"
      ],
      "metadata": {
        "id": "6k3yWn9818H0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMkhNlkFtbt7",
        "outputId": "325c34e7-bd39-4714-930e-8bc7bd473b80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(outputs.logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modellünk az első mondat esetében [-1,5607, 1,6123], a második esetében pedig [ 4,1692, -3,3464] értéket jelzett előre. Ezek nem valószínűségek, hanem logitek, a modell utolsó rétege által kiadott nyers, nem normalizált pontszámok. Ahhoz, hogy valószínűséggé alakíthassuk őket, át kell menniük egy SoftMax rétegen (minden Transformers modell logitokat ad ki, mivel a képzés veszteségfüggvénye általában az utolsó aktiválási függvényt, például a SoftMaxot, a tényleges veszteségfüggvénnyel, például a keresztentrópiával olvasztja össze):"
      ],
      "metadata": {
        "id": "O5lb93RQ2K0b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBG2N8hstbt7",
        "outputId": "4b5c7719-d99b-4a82-8545-366efa750ebf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most láthatjuk, hogy a modell az első mondat esetében [0,0402, 0,9598], a második esetében pedig [0,9995, 0,0005] értéket jósolt. Ezek felismerhető valószínűségi pontszámok.\n",
        "\n",
        "Az egyes pozíciókhoz tartozó címkékhez az id2label attribútumot vizsgálhatjuk meg a modell konfigurációjában"
      ],
      "metadata": {
        "id": "1ubk7MiU2mf0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wcAgub1tbt7",
        "outputId": "d55cd58f-2759-401b-9295-a9aea8fb048d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.config.id2label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most már megállapíthatjuk, hogy a modell a következőket jósolta:\n",
        "\n",
        "Az első mondat: NEGATÍV: 0,0402, POZITÍV: 0,9598.\n",
        "Második mondat: NEGATÍV: 0,9995, POZITÍV: 0,0005\n",
        "Sikeresen reprodukáltuk a csővezeték három lépését: előfeldolgozás tokenizátorokkal, a bemenetek átvezetése a modellen, és utófeldolgozás! Most szánjunk egy kis időt arra, hogy mélyebben elmerüljünk az egyes lépésekben.\n",
        "\n",
        "✏️ Próbálja ki! Válasszon ki két (vagy több) saját szöveget, és futtassa le őket a mondatelemző csővezetéken. Ezután ismételd meg magad az itt látott lépéseket, és ellenőrizd, hogy ugyanazokat az eredményeket kapod-e!"
      ],
      "metadata": {
        "id": "61CHl9r53CTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "raw_inputs = [\n",
        "    \"Szép az idő.\",\n",
        "    \"Utálom a matematikát\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "mvI8pE0A3QhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a51b6a25-2920-4678-aaec-12f7ecb045ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7658, 0.2342],\n",
            "        [0.8894, 0.1106]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ebben a részben közelebbről megnézzük a modell létrehozását és használatát. Az AutoModel osztályt fogjuk használni, ami akkor praktikus, ha bármilyen modellt szeretnénk egy ellenőrzőpontból betölteni.\n",
        "\n",
        "Ha azonban tudjuk, hogy milyen típusú modellt szeretnénk használni, akkor közvetlenül használhatjuk az architektúrát definiáló osztályt. Nézzük meg, hogyan működik ez egy BERT modellel.\n",
        "\n",
        "Egy transzformátor létrehozása\n",
        "A BERT modell inicializálásához először is be kell töltenünk egy konfigurációs objektumot:"
      ],
      "metadata": {
        "id": "OzZWiiBU3e4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyNfmTdT3LDN"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "# Building the config\n",
        "config = BertConfig()\n",
        "\n",
        "# Building the model from the config\n",
        "model = BertModel(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A konfiguráció számos attribútumot tartalmaz, amelyeket a modell felépítéséhez használnak:"
      ],
      "metadata": {
        "id": "CcwzbEr14Ilx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqC-E6643LDN",
        "outputId": "79419e8f-d896-4d89-b3e3-522ed46dfd95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"_attn_implementation_autoset\": true,\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.48.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bár még nem láttad, hogy ezek az attribútumok mit csinálnak, néhányat fel kell ismerned: a hidden_size attribútum a hidden_states vektor méretét határozza meg, a num_hidden_layers pedig a Transformer modell rétegeinek számát.\n",
        "\n",
        "##Különböző betöltési módszerek\n",
        "Egy modell létrehozása az alapértelmezett konfigurációból véletlenszerű értékekkel inicializálja azt:"
      ],
      "metadata": {
        "id": "dlCUR9RT4UG4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z4BP4a23LDO"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "config = BertConfig()\n",
        "model = BertModel(config)\n",
        "\n",
        "# Model is randomly initialized!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A modell ebben az állapotban is használható, de halandzsát fog kiadni; először be kell tanítani. A modellt a semmiből is betaníthatnánk az adott feladatra, de  ez hosszú időt és sok adatot igényelne, és nem elhanyagolható környezeti hatással járna. A felesleges és megkettőzött erőfeszítések elkerülése érdekében elengedhetetlen, hogy a már betanított modelleket megoszthassuk és újra felhasználhassuk.\n",
        "\n",
        "##Egy már betanított Transformer modell betöltése egyszerű - ezt a from_pretrained() metódussal tehetjük meg:"
      ],
      "metadata": {
        "id": "sI2PmBUI4mmH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dF-qT3h3LDO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "dc8df170043c4926b5159ad303d50604",
            "9f16b0697a2648609a207e7a30a2d25c",
            "da4d2f761cb4427484f9f307a5eb69e7",
            "a5efe587c8484cf99a023f9950f6a392",
            "1d3e6979fa2e49daa66eae152cef9540",
            "04f2038377d14180a58c858a7464d3be",
            "5ebf928b37b5493790be7795221c8645",
            "1a9ffb243c794bfc800a3fddce354810",
            "725ae13750064d6bb0784cbed652971c",
            "e2e4df79e5f848bbbc209dbbb34092bc",
            "62d02e42bcf440528323e4bab7a7f878",
            "03d23d6bb3184bc0ac93903710ca2493",
            "baea7f8244734ae8995238647facec2c",
            "70f3778f791343519b75dd60f4f47e63",
            "a12bb559db6c48ebb8c5f2ecec948ccf",
            "1ea07dacb9564d1fb11f6ca6e3764693",
            "97ea88943e714e3ca0abcc68ad220049",
            "ee0562b48cf74466952a8e4b29ea3e4e",
            "264b6a5a1de5451f8d4b0b7f14422fdb",
            "940c2361830f4bb99a711ed4017d973f",
            "cdfb33b884b945f09d2c9388c72b121e",
            "df0d77f71de84c22a59fcbdf88639c1c"
          ]
        },
        "outputId": "a54ed39a-8481-4b55-b9ce-1ae049117423"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc8df170043c4926b5159ad303d50604"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03d23d6bb3184bc0ac93903710ca2493"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fenti kódpéldában nem használtuk a BertConfig-et, helyette egy előre betanított modellt töltöttünk be a bert-bázisú azonosítón keresztül. Ez egy olyan modell ellenőrzőpont, amelyet maguk a BERT szerzői képeztek ki; további részleteket a modellkártyáján találhat róla.\n",
        "\n",
        "Ez a modell most az ellenőrzőpont összes súlyával inicializálódik. Közvetlenül használható következtetésre azokon a feladatokon, amelyekre betanították, és finomhangolható egy új feladaton is. Ha nem nulláról, hanem előre betanított súlyokkal képezzük, gyorsan jó eredményeket érhetünk el.\n",
        "\n",
        "A súlyok letöltésre és gyorsítótárba kerültek (így a from_pretrained() metódus jövőbeli hívásai nem töltik le őket újra) a cache mappába, amely alapértelmezés szerint a ~/.cache/huggingface/transformers mappába kerül. A HF_HOME környezeti változó beállításával testre szabhatja a cache mappát.\n",
        "\n",
        "A modell betöltéséhez használt azonosító lehet a Model Hubon lévő bármely modell azonosítója, amennyiben az kompatibilis a BERT architektúrával.\n",
        "\n",
        "Mentési módszerek\n",
        "A modell mentése ugyanolyan egyszerű, mint a betöltése - a save_pretrained() metódust használjuk, amely analóg a from_pretrained() metódussal:"
      ],
      "metadata": {
        "id": "9yf40QCQ5zQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMMTpdm73LDO"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"directory_on_my_computer\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls directory_on_my_computer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAKMvCj86TG1",
        "outputId": "31f4b524-d405-4001-86d2-a27b21ce31b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json  model.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ha vet egy pillantást a config.json fájlra, felismeri a modellarchitektúra felépítéséhez szükséges attribútumokat. Ez a fájl tartalmaz néhány metaadatot is, például azt, hogy honnan származik az ellenőrzőpont, és hogy milyen Transformers verziót használtál, amikor utoljára mentetted az ellenőrzőpontot.\n",
        "\n",
        "A pytorch_model.bin fájl az úgynevezett állapotszótár; ez tartalmazza a modell összes súlyát. A két fájl kéz a kézben jár; a konfiguráció a modelled felépítésének megismeréséhez szükséges, míg a modellsúlyok a modelled paraméterei.\n",
        "\n",
        "A Transformer modell használata következtetéshez\n",
        "Most, hogy már tudod, hogyan tölts be és ments el egy modellt, próbáljuk meg használni azt néhány előrejelzés elkészítéséhez. A Transformer modellek csak számokat tudnak feldolgozni - olyan számokat, amelyeket a tokenizáló generál. Mielőtt azonban a tokenizátorokról beszélnénk, vizsgáljuk meg, milyen bemeneteket fogad el a modell.\n",
        "\n",
        "A tokenizátorok gondoskodnak a bemenetek megfelelő keretrendszer tenzoraiba való átkonvertálásáról, de hogy segítsünk megérteni, mi történik, gyorsan megnézzük, mit kell tenni, mielőtt a bemeneteket elküldjük a modellnek.\n",
        "\n",
        "Tegyük fel, hogy van néhány szekvenciánk:"
      ],
      "metadata": {
        "id": "kM95cvPT6mEL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw0pBQt93LDO"
      },
      "outputs": [],
      "source": [
        "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tokenizáló ezeket szókincsindexekké alakítja át, amelyeket jellemzően bemeneti azonosítóknak nevezünk. Minden szekvencia most már egy számok listája! Az eredmény a következő kimenet:"
      ],
      "metadata": {
        "id": "7jhlD82Y60hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(sequences, return_tensors=\"pt\")\n",
        "print(inputs['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN5JRwg77VQI",
        "outputId": "388cc96a-0db4-4f1d-e98b-ed5f3d6f2748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 101, 7592,  999,  102],\n",
            "        [ 101, 4658, 1012,  102],\n",
            "        [ 101, 3835,  999,  102]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__79JOe23LDP"
      },
      "outputs": [],
      "source": [
        "encoded_sequences = [\n",
        "    [101, 7592, 999, 102],\n",
        "    [101, 4658, 1012, 102],\n",
        "    [101, 3835, 999, 102],\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ez a kódolt szekvenciák listája: listák listája. A tenzorok csak téglalap alakzatokat fogadnak el (gondoljunk a mátrixokra). Ez a \"tömb\" már téglalap alakú, így a tenzorrá alakítása egyszerű:\n",
        "\n",
        "A tenzorok használata a modell bemeneteként\n",
        "A tenzorok felhasználása a modellel rendkívül egyszerű - csak meghívjuk a modellt a bemenetekkel:"
      ],
      "metadata": {
        "id": "Comu65p48AUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyGnBOKs3LDP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "model_inputs = torch.tensor(encoded_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IFFyBm53LDP"
      },
      "outputs": [],
      "source": [
        "output = model(model_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bár a modell számos különböző argumentumot fogad el, csak a bemeneti azonosítókra van szükség. Később elmagyarázzuk, hogy a többi argumentum mire szolgál, és mikor van rájuk szükség, de előbb közelebbről meg kell néznünk a tokenizátorokat, amelyekből a Transformer modell által értelmezhető bemenetek felépülnek."
      ],
      "metadata": {
        "id": "C6tcfyM78dRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output\n",
        "#output.last_hidden_state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYNpQwXS7u7H",
        "outputId": "aa1c1357-2c43-4207-e87d-730edcb52854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 4.4496e-01,  4.8276e-01,  2.7797e-01,  ..., -5.4032e-02,\n",
              "           3.9393e-01, -9.4770e-02],\n",
              "         [ 2.4943e-01, -4.4093e-01,  8.1772e-01,  ..., -3.1917e-01,\n",
              "           2.2992e-01, -4.1172e-02],\n",
              "         [ 1.3668e-01,  2.2518e-01,  1.4502e-01,  ..., -4.6915e-02,\n",
              "           2.8224e-01,  7.5566e-02],\n",
              "         [ 1.1789e+00,  1.6738e-01, -1.8187e-01,  ...,  2.4671e-01,\n",
              "           1.0441e+00, -6.1972e-03]],\n",
              "\n",
              "        [[ 3.6436e-01,  3.2464e-02,  2.0258e-01,  ...,  6.0110e-02,\n",
              "           3.2451e-01, -2.0996e-02],\n",
              "         [ 7.1866e-01, -4.8725e-01,  5.1740e-01,  ..., -4.4012e-01,\n",
              "           1.4553e-01, -3.7545e-02],\n",
              "         [ 3.3223e-01, -2.3271e-01,  9.4876e-02,  ..., -2.5268e-01,\n",
              "           3.2172e-01,  8.1085e-04],\n",
              "         [ 1.2523e+00,  3.5754e-01, -5.1320e-02,  ..., -3.7840e-01,\n",
              "           1.0526e+00, -5.6255e-01]],\n",
              "\n",
              "        [[ 2.4042e-01,  1.4718e-01,  1.2110e-01,  ...,  7.6062e-02,\n",
              "           3.3564e-01,  2.8262e-01],\n",
              "         [ 6.5701e-01, -3.2787e-01,  2.4968e-01,  ..., -2.5919e-01,\n",
              "           2.0175e-01,  3.3275e-01],\n",
              "         [ 2.0160e-01,  1.5783e-01,  9.8970e-03,  ..., -3.8850e-01,\n",
              "           4.1307e-01,  3.9732e-01],\n",
              "         [ 1.0175e+00,  6.4387e-01, -7.8147e-01,  ..., -4.2109e-01,\n",
              "           1.0925e+00, -4.8456e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.6856,  0.5262,  1.0000,  ...,  1.0000, -0.6112,  0.9971],\n",
              "        [-0.6055,  0.4997,  0.9998,  ...,  0.9999, -0.6753,  0.9769],\n",
              "        [-0.7702,  0.5447,  0.9999,  ...,  1.0000, -0.4655,  0.9894]],\n",
              "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHLLY82t8qJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenizátorok\n",
        "A tokenizátorok az NLP-csatorna egyik központi eleme. Egyetlen célt szolgálnak: a szöveget a modell által feldolgozható adatokká alakítják. A modellek csak számokat tudnak feldolgozni, ezért a tokenizátoroknak a szöveges bemeneteinket számadatokká kell alakítaniuk. Ebben a szakaszban megvizsgáljuk, hogy pontosan mi történik a tokenizáló csővezetékben.\n",
        "\n",
        "Az NLP-feladatokban a feldolgozott adatok általában nyers szövegek. Íme egy példa ilyen szövegre:\n",
        "\n",
        "Jim Henson bábszínész volt\n",
        "\n",
        "A modellek azonban csak számokat tudnak feldolgozni, ezért meg kell találnunk a nyers szöveg számokká alakításának módját. Ezt teszik a tokenizátorok, és ennek számos módja van. A cél az, hogy megtaláljuk a legértelmesebb - vagyis a modell számára legértelmesebb - és lehetőleg a legkisebb reprezentációt.\n",
        "\n",
        "Nézzünk meg néhány példát a tokenizáló algoritmusokra, és próbáljuk megválaszolni a tokenizálással kapcsolatos néhány kérdést.\n",
        "\n",
        "Az első tokenizáló típus, ami eszünkbe jut, a szóalapú. Általában nagyon könnyen beállítható és használható, mindössze néhány szabály segítségével, és gyakran tisztességes eredményeket ad. Például az alábbi képen a cél a nyers szöveg szavakra bontása és számszerű ábrázolásuk megtalálása:\n",
        "\n",
        "![img](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/word_based_tokenization.svg)\n",
        "\n",
        "A szöveg felosztásának különböző módjai vannak. Például használhatunk szóközöket a szöveg szavakra történő tokenizálására a Python split() függvényének alkalmazásával:"
      ],
      "metadata": {
        "id": "RF97vFvyDQWu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWqr05P98lrG",
        "outputId": "36208bdd-baf2-4da4-d0a5-22f3963f09d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Jim', 'Henson', 'was', 'a', 'puppeteer']\n"
          ]
        }
      ],
      "source": [
        "tokenized_text = \"Jim Henson was a puppeteer\".split()\n",
        "print(tokenized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A szó-tokenizereknek vannak olyan változatai is, amelyek az írásjeleket extra szabályokkal kezelik.  Ezzel a  tokenizáló-típussal végül igencsak nagy \"szókincsekkel\" találkozhatunk, ahol a szókincs alatt a korpuszunkban szereplő egymástól független tokenek teljes számát értjük.**\n",
        "\n",
        "Minden szóhoz egy azonosító (ID) kerül  hozzárendelésre 0-val kezdve majd sorban fel  a szókincs nagyságáig. A modell ezeket az azonosítókat használja az egyes szavak beazonosítására.\n",
        "\n",
        "**Hátrányok**\n",
        "\n",
        "Ha egy teljes nyelvet le szeretnénk fedni  szó alapú tokenizálóval, rendelkeznünk kellene azonosítóval a nyelv minden egyes szavára, ami rengeteg tokent fog eredményezni. Például az angol nyelvben több mint 500 ezer szó van, tehát ha minden szóhoz tartozó inputazonsítóra egy saját térképet építenénk, annyi azonosítót kéne nyomon követnünk. Ezen kívül olyan szavak. pl. mint angolul a \"dog\" a  \"dogs\"-tól eltérően vannak ábrázolva, az elején a modellnek fogalma se lesz róla, hogy a  \"dog\" és a \"dogs\" hasonlóak: két egymással nem összefüggő szóként fogja  azonosítani őket. Ugyanez érvényes  más hasonló szavakra is: angolul mint például a \"run\" és a \"running\", amelyeket a modell eleinte nem érzékel majd hasonlókként.\n",
        "\n",
        "Végül egy egyedi tokenre is szükségünk van olyan szavak  ábrázolására, amelyek nincsenek benne a szókincsünkben.  Ezt nevezzük \"ismeretlen token\"-nek, amit gyakran \"[UNK]\" vagy \"<unk>\" szimbólumok jelképeznek. Általában rossz jelnek számít, ha a tokenizáló sok ilyen tokent produkál, mert a szó értelmezhető reprezentációját nem tudta előállítani, így menet közben információt veszítünk. A cél a szókincs kidolgozásakor az, hogy olyan módon tegyük, hogy a tokoenizáló a lehető legkevesebb szót jelölje meg ismeretlen jelölővel.\n",
        "\n",
        "Az ismeretlen tokenek számának csökkentésére szolgáló egyik módszer, ha egy szinttel lejjebb menünk, vagyis egy karakter alapú tokenizálót használunk.\n",
        "\n",
        "**Karakter alapú**\n",
        "\n",
        "*Karakter alapú* tokenizálók a szöveget szavak helyett karakterekre osztják szét. Ennek két elsődleges előnye van:\n",
        "\n",
        "* Sokkal kisebb szókincsre van szükségünk.\n",
        "* Sokkal kevesebb a szókincsen kívüli (ismeretlen) token, mivel minden szó felépíthető karakterekből.\n",
        "\n",
        "Viszont itt is felmerülnek bizonyos kérdések a szóközöket és írásjeleket illetően:\n",
        "\n",
        "![img](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/character_based_tokenization.svg)\n",
        "\n",
        "Ez a megközelítés sem tökéletes. Mivel az ábrázolás most már nem szavakon, hanem karaktereken alapul, azt mondhatjuk, hogy intuitíve kevésbé értelmes: minden egyes karakter önmagában nem jelent sokat, míg a szavak esetében ez a helyzet. Ez azonban megint csak nyelvenként változik; a kínai nyelvben például minden egyes karakter több információt hordoz, mint egy latin nyelvben egy karakter.\n",
        "\n",
        "Egy másik dolog, amit figyelembe kell venni, hogy a végén nagyon nagy mennyiségű token lesz, amit a modellünknek fel kell dolgoznia: míg egy szó egy szóalapú tokenizálóval csak egyetlen token lenne, addig karakterekké alakítva könnyen 10 vagy több token lehet belőle.\n",
        "\n",
        "Ahhoz, hogy mindkét világból a legjobbat kapjuk, használhatunk egy harmadik technikát, amely egyesíti a két megközelítést: az alszavas tokenizálást.\n",
        "\n",
        "\n",
        "##Rész-szavas (subword) tokenizáció\n",
        "\n",
        "A rész-szavas tokenizációs algoritmusok azon az elven alapulnak, hogy a gyakran használt szavakat nem szabad kisebb részekből álló szavakra felbontani, viszont a ritka szavakat érdemes értelmes részekre bontani.\n",
        "\n",
        "Például az \"annoyingly\" az angolban ritka szónak számítana, és szét lehetne bontani az  \"annoying\" és  \"ly\" elemekre. Mindkettő valószínűleg nagyobb gyakorisággal fog előfordulni önálló rész-szavakként, miközben az  \"annoyingly\" jelentésének megőrzéséhez hozzájárulnak az \"annoying\" és \"ly\" jelentései együtt.\n",
        "\n",
        "Egy példa arra, hogy a subword-tokenizáció hogyan bontaná fel a \"Let's do tokenization!\" szekvenciát:\n",
        "\n",
        "![img](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/bpe_subword.svg)\n",
        "\n"
      ],
      "metadata": {
        "id": "CIYYzH8JEtgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Részszavas megoldások jelentősége**\n",
        "\n",
        "Ezek a részszavak (subwords) rengeteg szemantikai jelentéssel bírnak: például a fentebb említett esetben a  \"tokenization\" fel lett bontva \"token\" és  \"ization\" jelentésű elemekre, ez a két token szemantikai jelentéshordozó, miközben helymegtakarító  ( mindössze két token szükséges egy hosszú szó ábrázolásához). Ez lehetővé teszi, hogy relatíve jó lefedettséggel  és kevés szókinccsel közel ismeretlen-mentes eredményt érjünk el.\n",
        "\n",
        "Ez a megközelítés különösen hasznos az agglutinatív nyelvekben, például törökben, ahol tetszőlegesen hosszú összetett szavakat lehet képezni al-szavak összeláncolásával.\n",
        "\n",
        "**Nem állunk meg itt**\n",
        "\n",
        "Nem meglepő módon, sok más technika létezik a fentieken kívül. Csak hogy párat említsünk:\n",
        "\n",
        "* Byte-szintű BPE, ahogy a GPT-2 használja\n",
        "* WordPiece, ahogy a BERT használja\n",
        "* SentencePiece vagy Unigram, ahogy több többnyelvű modell használja\n",
        "\n",
        "A fenti alapismeretek elegendőek, hogy elkezdjünk dolgozni az API-val.\n",
        "\n",
        "**Betöltés és mentés**\n",
        "\n",
        "A tokenizerek betöltése és mentése épp olyan egyszerű, mint a modelleké. Igazából, ugyanazokon a módszereken alapul:\n",
        "a `from_pretrained()` és a `save_pretrained()`. Ezek a metódusok betöltik/mentik a tokenizáló által használt algoritmust (hasonlóan a modell architektúrájához), valamint a szókincsét (hasonlóan a modell paramétereihez).  \n",
        "\n",
        "A BERT tokenizáló betöltése, ami ugyanazzal a checkpointtal trenelt, mint a BERT, ugyanúgy történik, mint a modell betöltése. De itt a `BertTokenizer` osztályt használjuk az `AutoTokenizer` helyett:\n"
      ],
      "metadata": {
        "id": "pJpYOOsuij4Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4Xc87s08lrG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "44e83438ee8a4acfa2d9b2c4bb0722b0",
            "0bdee739abc24b52805597e2095a4915",
            "d310a0dfbf22432293a55714bd883f52",
            "65943c32807149ca9b202902e8e1953a",
            "bf2fb43dd7b24ea9ab34d81629477339",
            "fa730998438e43109000c62c74bddb69",
            "84b557cfa069451ba5b4c590219b220d",
            "9486bd2c67fc4e0a98457ae1efde5a77",
            "516b39610ba242de91d6de369f82bf0e",
            "58c01f76467140d3922da1a68eab271e",
            "ed99143b9a2843f79e81a975a1a3898d",
            "8d4d21c498794fa0b9212fec1dfcb592",
            "78ca4cfdbf8c42e48016cdf1dda9fb7c",
            "c55990d643a040e094190c8f8b560172",
            "6cf36218a2dd40a1801a02be5a2560ae",
            "4ba1e3f08d814583ab8368cf63b8c149",
            "39c3c9f99b724124856b311c3736b6ef",
            "1fd7ecab75a4478d948c4b738d5e7f9a",
            "7c3e8c37ce064eb9bc1d32dbae68788d",
            "bd2431c17f144981b785a60c4572ebbf",
            "b3e7fbd0fd0947ef93edc2558b22f8c3",
            "63e8c3f10e7e4cedb59364648538f197",
            "e4debc66025c4854b4f236d18dd48fd5",
            "87d573f0c4954ce7a338fa69eae726ba",
            "7e9897b1859d44848ec8109c666fa34b",
            "7df91eccd4564d0aac8075a609b85192",
            "04fbc851f99b4f96bfbb52acd172d731",
            "4a3c990dd38843f7b923dc3209706184",
            "dfc25fe5c3414fdbbeafce6051a941fb",
            "f44a007036db462dbe42e3236476a3d7",
            "29066f6809f54da1b5d0f58f9bd127e1",
            "000920a62b8f418983ce5e8593434a3a",
            "707b845e5bb8407180722c61a6b3d674"
          ]
        },
        "outputId": "04fa7094-0355-4be1-9036-567dd654331c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44e83438ee8a4acfa2d9b2c4bb0722b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d4d21c498794fa0b9212fec1dfcb592"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4debc66025c4854b4f236d18dd48fd5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Az AutoModel-hez hasonlóan az AutoTokenizer osztály is megragadja a megfelelő tokenizáló osztályt a könyvtárban az ellenőrzőpont neve alapján, és közvetlenül használható bármely ellenőrzőponttal:"
      ],
      "metadata": {
        "id": "dkXZLGgMjGWP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVCVjM9t8lrH"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enIoA7dz8lrH",
        "outputId": "d4eda5c2-f58c-4486-c1d5-76ea09ee022c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7993, 170, 13809, 23763, 2443, 1110, 3014, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "tokenizer(\"Using a Transformer network is simple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hd7aBus8lrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b91dd440-bd2a-4f60-8ab6-21f09816a2ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('directory_on_my_computer/tokenizer_config.json',\n",
              " 'directory_on_my_computer/special_tokens_map.json',\n",
              " 'directory_on_my_computer/vocab.txt',\n",
              " 'directory_on_my_computer/added_tokens.json',\n",
              " 'directory_on_my_computer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "tokenizer.save_pretrained(\"directory_on_my_computer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Szöveg számokká alakítása\n",
        "\n",
        "Ez az eljárás: **kódolás (encoding)**néven ismert.  A kódolás egy kétlépcsős folyamat:\n",
        "\n",
        "Ahogy azt már láttuk, az első lépés a szöveg szavakra (vagy szórészekre,  írásjelekre stb.)  bontása, amit általában tokeneknek nevezünk. Számos szabály vonatkozhat a folyamatra, ezért a tokenizáló példányosításakor a modell nevét kell használni annak érdekében, hogy biztosan ugyanazon szabályokat alkalmazzuk, amelyeket a modell pretrainingje során használtak.\n",
        "\n",
        "A második lépés az, hogy ezeket a tokeneket számokká alakítjuk, hogy tenzort készíthessünk belőlük, és megadhassuk őket a modellnek. Ehhez a tokenizáló rendelkezik egy **szókinccsel**, ez az a rész, amit letöltünk, amikor létrehozzuk a  `from_pretrained()` metódussal. Ismét a modell előzetes betanítása során használt szókincset kell használnunk.\n",
        "\n",
        "E két lépés mélyebb megismerése érdekében külön-külön fogjuk kielemezni azokat. Fontos megjegyzés, hogy az elemzés során bizonyos módszereket  fogunk használni, amelyek elvégzik a tokenizáló pipeline egyes elemeit külön-külön mutatva az adott lépések közbenső eredményeit.\n",
        "\n",
        "**Tokeinizáció**\n",
        "\n",
        "A  **tokenize()**  metódus hajtja végre a tokenizációs folyamatot a tokenizálóban:\n"
      ],
      "metadata": {
        "id": "H6mMb_Sjkcj7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTAl2bkE8lrH",
        "outputId": "c663adbc-d2cd-4913-bd77-a463f5a7f64c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "sequence = \"Using a Transformer network is simple\"\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ennek a módszernek a kimenete egy karakterláncok vagy tokenek listája:"
      ],
      "metadata": {
        "id": "2TLVrvTQlnnY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrCRZ9Jg8lrI",
        "outputId": "ca906b79-c920-4e5e-ba1c-1959991bbea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7993, 170, 13809, 23763, 2443, 1110, 3014]\n"
          ]
        }
      ],
      "source": [
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensorok, mint input**\n",
        "\n",
        "Ezeket a kimeneteket, miután átalakítottuk őket a megfelelő keretrendszer tenzorává, a modell bemeneteként használhatjuk, ahogy azt ebben a fejezetben már korábban láttuk.\n",
        "\n",
        "✏️ **Próbáld ki!** Hajtsd végre az utolsó két lépést (tokenizáció és konvertálás inputazonsítókká)  a 2. fejezetben használt input kifejezéseken (\"I've been waiting for a Hugging Face course my whole life.\" and \"I hate this so much!\"). Ellenőrizd, hogy ugyanazokat az ids-eket kapod-e, amiket korábban!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lFYIDzqTmC63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = \"I've been waiting for an NLP course my whole life.\"\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzMdVX4CEood",
        "outputId": "b44355fa-cf8e-471d-96ad-ecc099f829ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[146, 112, 1396, 1151, 2613, 1111, 170, 20164, 10932, 2271, 7954, 1736, 1139, 2006, 1297, 119]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dekódolás**\n",
        "\n",
        "A dekódolás a fordítottja a tokenezésnek : a szókincs indexei alapján (vissza)kapjuk a karakterláncot. Ez a következőképpen hajtható végre a `decode()` metódussal:"
      ],
      "metadata": {
        "id": "eaiDus9aEaVi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiTVwkNv8lrI",
        "outputId": "29e4adc5-97af-4b71-ab63-336a15b10345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using a transformer network is simple\n"
          ]
        }
      ],
      "source": [
        "decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n",
        "print(decoded_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vegyük észre, hogy a dekódolási módszer nemcsak az indexeket alakítja vissza tokenekké, hanem az azonos szavak részét képező tokeneket is csoportosítja, hogy olvasható mondatot kapjunk. Ez a viselkedés rendkívül hasznos lesz, amikor olyan modelleket használunk, amelyek új szöveget jósolnak meg (akár egy promptból generált szöveget, akár szekvencia-szekvencia problémákat, például fordítást vagy összegzést).\n",
        "\n",
        "Mostanra már meg kell értenie azokat az atomi műveleteket, amelyeket egy tokenizáló kezelni tud: tokenizálás, azonosítókká alakítás és az azonosítók visszaalakítása karakterlánccá."
      ],
      "metadata": {
        "id": "Jtqs-DQFmkoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Több szekvencia kezelése\n",
        "\n",
        "**Új felmerülő kérdések**\n",
        "\n",
        "Az előző részben a legegyszerűbb alkalmazási esetet vettük át: következtetés lefuttatását egyetlen szekvencián.  Viszont az alábbi kérdések merülnek fel:\n",
        "\n",
        "* Hogyan kezeljük egyszerre több szekvenciát?\n",
        "* Hogyan kezeljük egyszerre több eltérő hosszúságú szekvenciát?\n",
        "* A szókincs-indexeken kívül vannak más input-típusok a modell optimális működéséhez?\n",
        "* Létezik túl hosszú szekvencia?\n",
        "\n",
        "Lássuk, milyen jellegű problémák merülhetnek fel, és hogyan oldhatók ezek meg a Transformers API használatával.\n",
        "\n",
        "**A modellek bemenetként egy \"köteget\" várnak**\n",
        "\n",
        "Az előző  feladat során láttad, hogyan konvertálhatók a szekvenciák számok listájává.  Ezek után a számok listáját átalakítjuk egy tenzorrá, és ezzel beadhatjuk a bemenetet a modellnek:\n"
      ],
      "metadata": {
        "id": "HvY2hNRk_H76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAwLVcLFmvjB",
        "outputId": "3ff73a59-c052-4f8d-cd34-3c57a95c0b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "too many indices for tensor of dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-2b9fc1b6cd40>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# This line will fail.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mwarn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   5069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5070\u001b[0m         \u001b[0;31m# Check only the first and last input IDs to reduce overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5071\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5072\u001b[0m             warn_string = (\n\u001b[1;32m   5073\u001b[0m                 \u001b[0;34m\"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = \"I've been waiting for an NLP course my whole life.\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "input_ids = torch.tensor(ids)\n",
        "# This line will fail.\n",
        "model(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VX1hQ1hFj8d",
        "outputId": "8dd7426e-d48a-42f6-9972-34d60a666668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Miért nem sikerült? \"A 2. szakaszban a pipeline lépéseit követtük.\n",
        "\n",
        "A probléma az, hogy egyetlen szekvenciát küldtünk a modellnek, miközben a  Transformers modellek alapértelmezésben több mondatot várnak el. Itt megpróbáltuk mindazt, amit a tokenizáló a színfalak mögött csinált, amikor egy szekvenciára alkalmaztuk. De ha jobban megnézzük, láthatjuk, hogy a tokenizáló nem egyszerűen csak átalakította a bemeneti azonosítók listáját egy tenzorrá, hanem egy dimenziót is hozzáadott hozzá:"
      ],
      "metadata": {
        "id": "QRcvDAXMFlXI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80TNBG6xmvjC",
        "outputId": "cdaaf5df-5ab0-4a26-b1c5-c0e4326b08d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102]])\n"
          ]
        }
      ],
      "source": [
        "tokenized_inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
        "print(tokenized_inputs[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjunk hozzá egy új dimenziót!"
      ],
      "metadata": {
        "id": "4t18mNQOlccf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvp8mPIxmvjC",
        "outputId": "3f8fd904-3eae-4dc1-e427-7e8653398802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012]])\n",
            "Logits: tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = \"I've been waiting for an NLP course my whole life.\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "input_ids = torch.tensor([ids]) # itt adtuk hozzá az új dimenziót!!!\n",
        "print(\"Input IDs:\", input_ids)\n",
        "\n",
        "output = model(input_ids)\n",
        "print(\"Logits:\", output.logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A kötegelés több mondat egyszerre történő elküldése a modellen keresztül. Ha csak egy mondatod van, akkor csak egyetlen szekvenciából építhetsz egy köteget:"
      ],
      "metadata": {
        "id": "sDIP-jxel4j0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ez a tétel két azonos szekvenciából áll!\n",
        "\n",
        "batched_ids = [ids, ids]\n",
        "\n",
        "Próbáld ki! Konvertáld ezt a batched_ids listát tenzorrá, és add át a modelleden. Ellenőrizze, hogy ugyanazt a logitet adja, mint korábban (de kétszer)!\n",
        "\n",
        "A kötegelés lehetővé teszi, hogy a modell akkor is működjön, ha több mondattal táplálod. Több szekvencia használata ugyanolyan egyszerű, mint egy szekvenciából álló batch létrehozása. Van azonban egy második probléma is. Amikor két (vagy több) mondatot próbál összefűzni, azok különböző hosszúságúak lehetnek. Ha dolgozott már tenzorokkal, akkor tudja, hogy azoknak téglalap alakúnak kell lenniük, így a bemeneti azonosítók listáját nem tudja közvetlenül tenzorrá alakítani. Ennek a problémának a kiküszöbölésére általában kitöltjük a bemeneteket.\n",
        "\n",
        "A bemenetek kitöltése\n",
        "A következő listát nem lehet tenzorrá alakítani:"
      ],
      "metadata": {
        "id": "PLCSiSz5mIG4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltI_iER0mvjD"
      },
      "outputs": [],
      "source": [
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200]\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hogy ezt megkerüljük, a tenzorok téglalap alakúvá tételéhez kitöltést használunk. A kitöltés biztosítja, hogy minden mondatunk azonos hosszúságú legyen azáltal, hogy a kevesebb értékkel rendelkező mondatokhoz hozzáadunk egy speciális szót, a padding tokent. Ha például 10 mondatunk van 10 szóval és 1 mondatunk 20 szóval, a padding biztosítja, hogy minden mondat 20 szóval rendelkezzen. Példánkban az eredményül kapott tenzor így néz ki:"
      ],
      "metadata": {
        "id": "NKHxxOMxnInB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8rJ9fj0mvjD"
      },
      "outputs": [],
      "source": [
        "padding_id = 100\n",
        "\n",
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200, padding_id],\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pad token azonosítója a tokenizer.pad_token_id mezőben található. Használjuk ezt, és küldjük át a két mondatunkat a modellen egyenként és összevontan:"
      ],
      "metadata": {
        "id": "GpeHJEMWsAgH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqzRHxlXmvjD",
        "outputId": "8c6e37d6-bbf1-4452-b84a-fbc87ae1e7b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.5694, -1.3895]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 1.5694, -1.3895],\n",
            "        [ 1.3374, -1.2163]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence1_ids = [[200, 200, 200]]\n",
        "sequence2_ids = [[200, 200]]\n",
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200, tokenizer.pad_token_id],\n",
        "]\n",
        "\n",
        "print(model(torch.tensor(sequence1_ids)).logits)\n",
        "print(model(torch.tensor(sequence2_ids)).logits)\n",
        "print(model(torch.tensor(batched_ids)).logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valami baj van a logitokkal a kötegelt előrejelzéseinkben: a második sornak meg kellene egyeznie a második mondat logitjaival, de teljesen más értékeket kaptunk!\n",
        "\n",
        "Ennek az az oka, hogy a Transformer-modellek legfontosabb jellemzője a figyelemrétegek, amelyek kontextusba helyezik az egyes tokeneket. Ezek figyelembe veszik a kitöltő tokeneket, mivel egy szekvencia összes tokenjére figyelnek. Ahhoz, hogy ugyanazt az eredményt kapjuk, amikor különböző hosszúságú egyes mondatokat engedünk át a modellen, vagy amikor egy köteget engedünk át ugyanazokkal a mondatokkal és kitöltéssel, meg kell mondanunk ezeknek a figyelemrétegeknek, hogy hagyják figyelmen kívül a kitöltő tokeneket. Ezt egy figyelemmaszk használatával érhetjük el.\n",
        "\n",
        "##Figyelem maszkok\n",
        "\n",
        "A figyelemmaszkok a bemeneti azonosítók tenzorával pontosan megegyező alakú tenzorok, amelyek 0-akkal és 1-ekkel vannak kitöltve: az 1-ek azt jelzik, hogy a megfelelő tokenekre figyelni kell, a 0-ak pedig azt, hogy a megfelelő tokenekre nem kell figyelni (azaz a modell figyelmi rétegei figyelmen kívül hagyják őket).\n",
        "\n",
        "Egészítsük ki az előző példát egy figyelemmaszkkal:"
      ],
      "metadata": {
        "id": "X5rmfIIosb36"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtPWBtW4mvjE",
        "outputId": "e6818cad-0155-49f5-c063-248a92b64e65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.5694, -1.3895],\n",
            "        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200, tokenizer.pad_token_id],\n",
        "]\n",
        "\n",
        "attention_mask = [\n",
        "    [1, 1, 1],\n",
        "    [1, 1, 0],\n",
        "]\n",
        "\n",
        "outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))\n",
        "print(outputs.logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most ugyanezeket a logiteket kapjuk a tétel második mondatára.\n",
        "\n",
        "Figyeljük meg, hogy a második szekvencia utolsó értéke egy kitöltési azonosító, ami a figyelemmaszkban 0 érték.\n",
        "\n",
        "✏️ Próbálja ki! Alkalmazza a tokenizálást kézzel a 2. pontban használt két mondatra (\"Egész életemben egy HuggingFace-tanfolyamra vártam.\" és \"Annyira utálom ezt!\"). Vezesse át őket a modellen, és ellenőrizze, hogy ugyanazokat a logaritmusokat kapja-e, mint a 2. szakaszban. Most a padding token segítségével halmozza össze őket, majd hozza létre a megfelelő figyelemmaszkot. Ellenőrizze, hogy a modellen való áthaladáskor ugyanazokat az eredményeket kapja!\n",
        "\n",
        "##Hosszabb szekvenciák\n",
        "A transzformátor modellek esetében van egy korlát a szekvenciák hosszának, amelyeket át tudunk adni a modelleknek. A legtöbb modell 512 vagy 1024 tokenig terjedő szekvenciákat kezel, és összeomlik, ha hosszabb szekvenciák feldolgozására kérik. Erre a problémára két megoldás létezik:\n",
        "\n",
        "Használjunk olyan modellt, amely hosszabb támogatott szekvenciahosszúságú.\n",
        "Csonkítsa meg a szekvenciákat.\n",
        "\n",
        "Ellenkező esetben a max_sequence_length paraméter megadásával csonkítsa meg a szekvenciákat:"
      ],
      "metadata": {
        "id": "qIz6weXftHzA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39Cpy65hmvjE"
      },
      "outputs": [],
      "source": [
        "max_sequence_length = 256\n",
        "sequence = sequence[:max_sequence_length]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Összeállítjuk az egészet\n",
        "\n",
        "\n",
        "Azonban, ahogy a 2. szakaszban láttuk, a 🤗 Transformers API mindezt el tudja intézni helyettünk egy magas szintű függvénnyel, amelybe itt belemerülünk. Ha közvetlenül a mondaton hívjuk meg a tokenizálót, akkor olyan bemeneteket kapunk vissza, amelyek készen állnak arra, hogy átmenjenek a modellünkön:"
      ],
      "metadata": {
        "id": "-cesuz_otzPz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37y97ZUOtsk2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = \"I've been waiting for an NLP course my whole life.\"\n",
        "\n",
        "model_inputs = tokenizer(sequence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Itt a model_inputs változó tartalmazza mindazt, ami a modell jó működéséhez szükséges. A DistilBERT esetében ez magában foglalja a bemeneti azonosítókat, valamint a figyelmi maszkot. Más modellek, amelyek további bemeneteket fogadnak el, azokat is a tokenizáló objektum adja ki.\n",
        "\n",
        "Amint azt az alábbi néhány példában látni fogjuk, ez a módszer nagyon hatékony. Először is, képes egyetlen szekvenciát tokenizálni:"
      ],
      "metadata": {
        "id": "GSzOO0jE3vMa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_Y4SpWutsk3"
      },
      "outputs": [],
      "source": [
        "sequence = \"I've been waiting for an NLP course my whole life.\"\n",
        "\n",
        "model_inputs = tokenizer(sequence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Egyszerre több szekvenciát is kezel, az API változatlanul hagyásával:"
      ],
      "metadata": {
        "id": "8671Qiq73_C4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xXWpr4ptsk3"
      },
      "outputs": [],
      "source": [
        "sequences = [\"I've been waiting for an NLP course my whole life.\", \"So have I!\"]\n",
        "\n",
        "model_inputs = tokenizer(sequences)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Többféle padding elérhető:"
      ],
      "metadata": {
        "id": "ND4I9gv54Cyf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBHRtYzltsk3"
      },
      "outputs": [],
      "source": [
        "# Will pad the sequences up to the maximum sequence length\n",
        "model_inputs = tokenizer(sequences, padding=\"longest\")\n",
        "\n",
        "# Will pad the sequences up to the model max length\n",
        "# (512 for BERT or DistilBERT)\n",
        "model_inputs = tokenizer(sequences, padding=\"max_length\")\n",
        "\n",
        "# Will pad the sequences up to the specified max length\n",
        "model_inputs = tokenizer(sequences, padding=\"max_length\", max_length=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Többféle csonkolás érhető el:"
      ],
      "metadata": {
        "id": "127F2jHr4WEA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1uVwA85tsk4"
      },
      "outputs": [],
      "source": [
        "sequences = [\"I've been waiting for an NLP course my whole life.\", \"So have I!\"]\n",
        "\n",
        "# Will truncate the sequences that are longer than the model max length\n",
        "# (512 for BERT or DistilBERT)\n",
        "model_inputs = tokenizer(sequences, truncation=True)\n",
        "\n",
        "# Will truncate the sequences that are longer than the specified max length\n",
        "model_inputs = tokenizer(sequences, max_length=8, truncation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tokenizáló objektum képes kezelni a konkrét keretrendszer-tenzorokká való átalakítást, amelyeket aztán közvetlenül elküldhetünk a modellnek. A következő kódpéldában például arra kérjük a tokenizert, hogy adja vissza a különböző keretrendszerek tenzorait - a \"pt\" a PyTorch tenzorokat, a \"tf\" a TensorFlow tenzorokat, az \"np\" pedig a NumPy tömböket adja vissza:"
      ],
      "metadata": {
        "id": "BV23KKXH64Zt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuZBNmActsk4"
      },
      "outputs": [],
      "source": [
        "sequences = [\"I've been waiting for an NLP course my whole life.\", \"So have I!\"]\n",
        "\n",
        "# Returns PyTorch tensors\n",
        "model_inputs = tokenizer(sequences, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "# Returns TensorFlow tensors\n",
        "model_inputs = tokenizer(sequences, padding=True, return_tensors=\"tf\")\n",
        "\n",
        "# Returns NumPy arrays\n",
        "model_inputs = tokenizer(sequences, padding=True, return_tensors=\"np\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Különleges tokenek\n",
        "Ha megnézzük a tokenizáló által visszaadott bemeneti azonosítókat, láthatjuk, hogy egy kicsit eltérnek a korábbiaktól:"
      ],
      "metadata": {
        "id": "svZabALj7BmZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiGcbU84tsk4",
        "outputId": "0c69ed77-f933-438d-a20f-6600fcb53fa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102]\n",
            "[1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012]\n"
          ]
        }
      ],
      "source": [
        "sequence = \"I've been waiting for an NLP course my whole life.\"\n",
        "\n",
        "model_inputs = tokenizer(sequence)\n",
        "print(model_inputs[\"input_ids\"])\n",
        "\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Egy token azonosítót adtunk hozzá az elején, egyet pedig a végén. Dekódoljuk a fenti két ID-sorozatot, hogy lássuk, miről van szó:"
      ],
      "metadata": {
        "id": "lKntG5b17Zgw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J13EXwQAtsk5",
        "outputId": "d68e46db-0ed5-4dbd-cdc0-817c3b708aba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] i've been waiting for a huggingface course my whole life. [SEP]\n",
            "i've been waiting for a huggingface course my whole life.\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(model_inputs[\"input_ids\"]))\n",
        "print(tokenizer.decode(ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tokenizáló hozzáadta a [CLS] speciális szót az elejére és a [SEP] speciális szót a végére. Ez azért van, mert a modell előzetesen ezekkel lett betanítva, így ahhoz, hogy a következtetésnél is ugyanolyan eredményt kapjunk, ezeket is hozzá kell adnunk. Megjegyezzük, hogy egyes modellek nem adnak hozzá speciális szavakat, vagy különböző szavakat adnak hozzá; a modellek ezeket a speciális szavakat is csak az elején vagy csak a végén adhatják hozzá. A tokenizáló mindenesetre tudja, hogy melyek az elvártak, és ezt elintézi helyettünk.\n",
        "\n",
        "##Befejezés: A tokenizálótól a modellig\n",
        "Most, hogy láttuk az összes egyes lépést, amit a tokenizáló objektum a szövegekre alkalmazva alkalmaz, nézzük meg még egyszer utoljára, hogyan tudja kezelni a többszörös szekvenciákat (kitöltés!), a nagyon hosszú szekvenciákat (csonkítás!) és a többféle tenzorokat a fő API-jával:"
      ],
      "metadata": {
        "id": "xul39rJ97xL-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_MWWR4Itsk5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "sequences = [\"I've been waiting for an NLP course my whole life.\", \"So have I!\"]\n",
        "\n",
        "tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "output = model(**tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McuqR9pfgV6k",
        "outputId": "c0470d8d-c881-4dab-f195-6d778dab099b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.5607,  1.6123],\n",
              "        [-3.6183,  3.9137]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gb1g77RkgW_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}